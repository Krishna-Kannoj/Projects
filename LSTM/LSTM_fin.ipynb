{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3gT9jipNwPF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f5f930ad-553a-4b8a-e458-7c778cef67ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7d408e2f70>]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "df=pd.read_csv('NSEBANK.csv')\n",
        "df = df[800:]\n",
        "df1=df.reset_index()['Close']\n",
        "df2=df.reset_index()['Open']\n",
        "df3=df.reset_index()['High']\n",
        "df4=df.reset_index()['Low']\n",
        "df1 = df1.dropna()\n",
        "df2 = df2.dropna()\n",
        "df3 = df3.dropna()\n",
        "df4 = df4.dropna()\n",
        "\n",
        "plt.plot(df1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler1=MinMaxScaler(feature_range=(0,1))\n",
        "scaler2=MinMaxScaler(feature_range=(0,1))\n",
        "scaler3=MinMaxScaler(feature_range=(0,1))\n",
        "scaler4=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler1.fit_transform(np.array(df1).reshape(-1,1))\n",
        "df2=scaler2.fit_transform(np.array(df2).reshape(-1,1))\n",
        "df3=scaler3.fit_transform(np.array(df3).reshape(-1,1))\n",
        "df4=scaler4.fit_transform(np.array(df4).reshape(-1,1))\n",
        "\n",
        "training_size=int(len(df1)*0.65) #len(df1) = len(df2) = ...\n",
        "test_size=len(df1)-training_size\n",
        "train_data_close,test_data_close=df1[0:training_size,:],df1[training_size:len(df1),:1]\n",
        "train_data_open,test_data_open=df2[0:training_size,:],df2[training_size:len(df2),:1]\n",
        "train_data_high,test_data_high=df3[0:training_size,:],df3[training_size:len(df3),:1]\n",
        "train_data_low,test_data_low=df4[0:training_size,:],df4[training_size:len(df4),:1]\n",
        "\n",
        "training_size,test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zvo7G0MN2xk",
        "outputId": "cfd40a01-067f-47f0-ea65-84008e0bd183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282, 153)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "\n",
        "time_step = 50\n",
        "X_train_C, y_train_C = create_dataset(train_data_close, time_step)\n",
        "X_test_C, ytest_C = create_dataset(test_data_close, time_step)\n",
        "\n",
        "X_train_C =X_train_C.reshape(X_train_C.shape[0],X_train_C.shape[1] , 1)\n",
        "X_test_C = X_test_C.reshape(X_test_C.shape[0],X_test_C.shape[1] , 1)\n",
        "\n",
        "X_train_O, y_train_O = create_dataset(train_data_open, time_step)\n",
        "X_test_O, ytest_O = create_dataset(test_data_open, time_step)\n",
        "\n",
        "X_train_O =X_train_O.reshape(X_train_O.shape[0],X_train_O.shape[1] , 1)\n",
        "X_test_O = X_test_O.reshape(X_test_O.shape[0],X_test_O.shape[1] , 1)\n",
        "\n",
        "X_train_H, y_train_H = create_dataset(train_data_high, time_step)\n",
        "X_test_H, ytest_H = create_dataset(test_data_high, time_step)\n",
        "\n",
        "X_train_H =X_train_H.reshape(X_train_H.shape[0],X_train_H.shape[1] , 1)\n",
        "X_test_H = X_test_H.reshape(X_test_H.shape[0],X_test_H.shape[1] , 1)\n",
        "\n",
        "X_train_L, y_train_L = create_dataset(train_data_low, time_step)\n",
        "X_test_L, ytest_L = create_dataset(test_data_low, time_step)\n",
        "\n",
        "X_train_L =X_train_L.reshape(X_train_L.shape[0],X_train_L.shape[1] , 1)\n",
        "X_test_L = X_test_L.reshape(X_test_L.shape[0],X_test_L.shape[1] , 1)\n",
        "\n",
        "X_test_C.shape, ytest_C.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQZuqv6N3ja",
        "outputId": "4a12515c-89b1-4e35-ecd6-181dc425d857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((102, 50, 1), (102,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model1=Sequential()\n",
        "model1.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\n",
        "model1.add(LSTM(50))\n",
        "model1.add(Dense(1))\n",
        "model1.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "model1.fit(X_train_C,y_train_C,validation_data=(X_test_C,ytest_C),epochs=100,batch_size=64,verbose=1)\n",
        "\n",
        "\n",
        "model2=Sequential()\n",
        "model2.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\n",
        "model2.add(LSTM(50))\n",
        "model2.add(Dense(1))\n",
        "model2.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "model2.fit(X_train_O,y_train_O,validation_data=(X_test_O,ytest_O),epochs=100,batch_size=64,verbose=1)\n",
        "\n",
        "\n",
        "model3=Sequential()\n",
        "model3.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\n",
        "model3.add(LSTM(50))\n",
        "model3.add(Dense(1))\n",
        "model3.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "model3.fit(X_train_H,y_train_H,validation_data=(X_test_H,ytest_H),epochs=100,batch_size=64,verbose=1)\n",
        "\n",
        "model4=Sequential()\n",
        "model4.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\n",
        "model4.add(LSTM(50))\n",
        "model4.add(Dense(1))\n",
        "model4.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "model4.fit(X_train_L,y_train_L,validation_data=(X_test_L,ytest_L),epochs=100,batch_size=64,verbose=1)"
      ],
      "metadata": {
        "id": "1Z0xvnsGN3mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f163032d-ae31-4135-c908-d02b4d1b67b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 387ms/step - loss: 0.1816 - val_loss: 0.0576\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0208 - val_loss: 0.0400\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0379 - val_loss: 0.0125\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0100 - val_loss: 0.0265\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0176 - val_loss: 0.0295\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0149 - val_loss: 0.0175\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0095 - val_loss: 0.0113\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0112 - val_loss: 0.0113\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0106 - val_loss: 0.0115\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0087 - val_loss: 0.0141\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0091 - val_loss: 0.0143\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0088 - val_loss: 0.0120\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0082 - val_loss: 0.0105\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0082 - val_loss: 0.0102\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0080 - val_loss: 0.0107\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0078 - val_loss: 0.0109\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0074 - val_loss: 0.0095\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0071 - val_loss: 0.0096\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0070 - val_loss: 0.0097\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0069 - val_loss: 0.0092\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0068 - val_loss: 0.0086\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0066 - val_loss: 0.0086\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0065 - val_loss: 0.0089\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0064 - val_loss: 0.0083\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0063 - val_loss: 0.0079\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0061 - val_loss: 0.0081\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0060 - val_loss: 0.0083\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0059 - val_loss: 0.0076\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0057 - val_loss: 0.0075\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0056 - val_loss: 0.0076\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0055 - val_loss: 0.0073\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0053 - val_loss: 0.0070\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0053 - val_loss: 0.0070\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0052 - val_loss: 0.0073\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0052 - val_loss: 0.0067\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0051 - val_loss: 0.0067\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0051 - val_loss: 0.0071\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0050 - val_loss: 0.0065\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0050 - val_loss: 0.0069\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0049 - val_loss: 0.0068\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0049 - val_loss: 0.0065\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0048 - val_loss: 0.0067\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0048 - val_loss: 0.0068\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0047 - val_loss: 0.0063\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0047 - val_loss: 0.0064\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0047 - val_loss: 0.0064\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0047 - val_loss: 0.0064\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0049 - val_loss: 0.0070\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0047 - val_loss: 0.0058\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0046 - val_loss: 0.0058\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0047 - val_loss: 0.0065\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0045 - val_loss: 0.0055\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0044 - val_loss: 0.0056\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0043 - val_loss: 0.0056\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0043 - val_loss: 0.0055\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0042 - val_loss: 0.0058\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0055\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.0053\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0041 - val_loss: 0.0059\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0041 - val_loss: 0.0051\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0041 - val_loss: 0.0052\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0040 - val_loss: 0.0056\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0040 - val_loss: 0.0051\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0040 - val_loss: 0.0049\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0055\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0042 - val_loss: 0.0049\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0053\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0045\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0038 - val_loss: 0.0048\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0048\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0036 - val_loss: 0.0045\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0036 - val_loss: 0.0044\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0032 - val_loss: 0.0037\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0032 - val_loss: 0.0039\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0033 - val_loss: 0.0033\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0032 - val_loss: 0.0040\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 448ms/step - loss: 0.2400 - val_loss: 0.1188\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0446 - val_loss: 0.0264\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 108ms/step - loss: 0.0368 - val_loss: 0.0151\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0120 - val_loss: 0.0228\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 141ms/step - loss: 0.0165 - val_loss: 0.0291\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0157 - val_loss: 0.0177\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0095 - val_loss: 0.0112\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0106 - val_loss: 0.0113\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0105 - val_loss: 0.0111\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0086 - val_loss: 0.0139\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0091 - val_loss: 0.0139\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0087 - val_loss: 0.0115\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0083 - val_loss: 0.0101\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0082 - val_loss: 0.0101\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0079 - val_loss: 0.0107\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0075 - val_loss: 0.0098\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0073 - val_loss: 0.0096\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0072 - val_loss: 0.0096\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0071 - val_loss: 0.0096\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0070 - val_loss: 0.0090\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0069 - val_loss: 0.0089\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0067 - val_loss: 0.0090\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0067 - val_loss: 0.0090\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0066 - val_loss: 0.0085\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0065 - val_loss: 0.0082\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0064 - val_loss: 0.0084\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0062 - val_loss: 0.0082\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0062 - val_loss: 0.0080\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 104ms/step - loss: 0.0061 - val_loss: 0.0080\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 1s 182ms/step - loss: 0.0060 - val_loss: 0.0078\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0059 - val_loss: 0.0078\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0058 - val_loss: 0.0077\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0057 - val_loss: 0.0077\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0057 - val_loss: 0.0076\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0056 - val_loss: 0.0072\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0055 - val_loss: 0.0075\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0055 - val_loss: 0.0074\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0054 - val_loss: 0.0070\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0054 - val_loss: 0.0074\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0053 - val_loss: 0.0071\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0053 - val_loss: 0.0071\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0053 - val_loss: 0.0073\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0052 - val_loss: 0.0069\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0053 - val_loss: 0.0071\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0052 - val_loss: 0.0068\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0051 - val_loss: 0.0072\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0052 - val_loss: 0.0068\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0051 - val_loss: 0.0070\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0051 - val_loss: 0.0068\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0050 - val_loss: 0.0067\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0050 - val_loss: 0.0066\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0050 - val_loss: 0.0070\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0050 - val_loss: 0.0064\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0049 - val_loss: 0.0069\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0049 - val_loss: 0.0064\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0049 - val_loss: 0.0063\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0048 - val_loss: 0.0066\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0048 - val_loss: 0.0063\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0047 - val_loss: 0.0066\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0048 - val_loss: 0.0062\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0049 - val_loss: 0.0063\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0046 - val_loss: 0.0066\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0045 - val_loss: 0.0059\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.0061\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0044 - val_loss: 0.0057\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0045 - val_loss: 0.0058\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0044 - val_loss: 0.0059\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.0056\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0060\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0043 - val_loss: 0.0055\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0044 - val_loss: 0.0058\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0042 - val_loss: 0.0053\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0043 - val_loss: 0.0056\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0041 - val_loss: 0.0056\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0042 - val_loss: 0.0054\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0042 - val_loss: 0.0054\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0041 - val_loss: 0.0051\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0044 - val_loss: 0.0053\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0043 - val_loss: 0.0051\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0051\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0044 - val_loss: 0.0052\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.0052\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0042 - val_loss: 0.0049\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0039 - val_loss: 0.0055\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0038 - val_loss: 0.0053\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 97ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0055\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 0.0046\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0052\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.0048\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0035 - val_loss: 0.0051\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 348ms/step - loss: 0.1698 - val_loss: 0.0774\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0265 - val_loss: 0.0281\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0330 - val_loss: 0.0120\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0107 - val_loss: 0.0223\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0149 - val_loss: 0.0250\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0129 - val_loss: 0.0141\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0082 - val_loss: 0.0098\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0100 - val_loss: 0.0097\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0090 - val_loss: 0.0109\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0078 - val_loss: 0.0127\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0081 - val_loss: 0.0114\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0074 - val_loss: 0.0094\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0073 - val_loss: 0.0088\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0072 - val_loss: 0.0091\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0070 - val_loss: 0.0097\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0068 - val_loss: 0.0090\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0067 - val_loss: 0.0083\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0065 - val_loss: 0.0086\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0064 - val_loss: 0.0089\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0063 - val_loss: 0.0080\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0062 - val_loss: 0.0075\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0061 - val_loss: 0.0079\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0060 - val_loss: 0.0080\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0058 - val_loss: 0.0073\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.0057 - val_loss: 0.0073\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0055 - val_loss: 0.0069\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0054 - val_loss: 0.0071\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0053 - val_loss: 0.0066\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0052 - val_loss: 0.0069\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0051 - val_loss: 0.0065\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0050 - val_loss: 0.0064\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0050 - val_loss: 0.0064\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0048 - val_loss: 0.0065\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0049 - val_loss: 0.0062\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0048 - val_loss: 0.0059\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0046 - val_loss: 0.0066\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0047 - val_loss: 0.0059\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0046 - val_loss: 0.0059\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0046 - val_loss: 0.0058\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0044 - val_loss: 0.0055\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.0060\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0044 - val_loss: 0.0055\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.0059\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0044 - val_loss: 0.0056\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0043 - val_loss: 0.0053\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0044 - val_loss: 0.0059\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0042 - val_loss: 0.0051\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0043 - val_loss: 0.0059\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0052\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0041 - val_loss: 0.0050\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0040 - val_loss: 0.0056\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0040 - val_loss: 0.0049\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0040 - val_loss: 0.0049\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0049\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0039 - val_loss: 0.0049\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0047\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0048\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0038 - val_loss: 0.0047\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0037 - val_loss: 0.0047\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0037 - val_loss: 0.0047\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0035 - val_loss: 0.0048\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0033 - val_loss: 0.0048\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0031 - val_loss: 0.0041\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0029 - val_loss: 0.0036\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0027 - val_loss: 0.0033\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0027 - val_loss: 0.0029\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0026 - val_loss: 0.0034\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0031 - val_loss: 0.0028\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0028 - val_loss: 0.0036\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0028 - val_loss: 0.0028\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.0025 - val_loss: 0.0026\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 5s 355ms/step - loss: 0.2932 - val_loss: 0.1801\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0823 - val_loss: 0.0196\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0211 - val_loss: 0.0334\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0303 - val_loss: 0.0122\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0114 - val_loss: 0.0235\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0157 - val_loss: 0.0280\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0154 - val_loss: 0.0199\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0106 - val_loss: 0.0125\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.0096 - val_loss: 0.0110\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0105 - val_loss: 0.0108\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0093 - val_loss: 0.0118\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0087 - val_loss: 0.0134\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0091 - val_loss: 0.0135\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0087 - val_loss: 0.0117\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0084 - val_loss: 0.0103\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0083 - val_loss: 0.0102\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0081 - val_loss: 0.0107\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0079 - val_loss: 0.0110\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0079 - val_loss: 0.0108\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0078 - val_loss: 0.0102\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0076 - val_loss: 0.0098\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0075 - val_loss: 0.0096\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0075 - val_loss: 0.0094\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0073 - val_loss: 0.0097\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0074 - val_loss: 0.0098\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0072 - val_loss: 0.0090\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0072 - val_loss: 0.0088\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.0070 - val_loss: 0.0093\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0069 - val_loss: 0.0091\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0069 - val_loss: 0.0088\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0068 - val_loss: 0.0086\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0067 - val_loss: 0.0083\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0066 - val_loss: 0.0084\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0065 - val_loss: 0.0083\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0064 - val_loss: 0.0083\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0063 - val_loss: 0.0080\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0063 - val_loss: 0.0078\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0062 - val_loss: 0.0081\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0061 - val_loss: 0.0078\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0060 - val_loss: 0.0074\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0059 - val_loss: 0.0076\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0059 - val_loss: 0.0079\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0058 - val_loss: 0.0073\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0058 - val_loss: 0.0072\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0057 - val_loss: 0.0076\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0057 - val_loss: 0.0073\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0056 - val_loss: 0.0073\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0056 - val_loss: 0.0071\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0055 - val_loss: 0.0069\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0055 - val_loss: 0.0075\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0055 - val_loss: 0.0069\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0056 - val_loss: 0.0067\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.0053 - val_loss: 0.0076\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0056 - val_loss: 0.0070\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0054 - val_loss: 0.0065\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0053 - val_loss: 0.0071\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0053 - val_loss: 0.0069\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0052 - val_loss: 0.0067\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0052 - val_loss: 0.0065\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0052 - val_loss: 0.0067\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0052 - val_loss: 0.0066\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0051 - val_loss: 0.0063\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0050 - val_loss: 0.0066\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0051 - val_loss: 0.0064\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0050 - val_loss: 0.0064\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0050 - val_loss: 0.0062\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 79ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0047 - val_loss: 0.0058\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0048 - val_loss: 0.0059\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0050 - val_loss: 0.0060\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0047 - val_loss: 0.0054\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0049 - val_loss: 0.0062\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0047 - val_loss: 0.0054\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0045 - val_loss: 0.0053\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0044 - val_loss: 0.0056\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0044 - val_loss: 0.0054\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0044 - val_loss: 0.0051\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0043 - val_loss: 0.0056\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0043 - val_loss: 0.0048\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0042 - val_loss: 0.0052\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0042 - val_loss: 0.0047\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0041 - val_loss: 0.0045\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0040 - val_loss: 0.0050\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0039 - val_loss: 0.0052\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0038 - val_loss: 0.0041\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 80ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 83ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.0035 - val_loss: 0.0036\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0032 - val_loss: 0.0040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7cd971fd60>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model1.save('my_model1.h5')\n",
        "model2.save('my_model2.h5')\n",
        "model3.save('my_model3.h5')\n",
        "model4.save('my_model4.h5')\n",
        "\n",
        "# model1 = load_model('my_model1.h5')\n",
        "# model2 = load_model('my_model2.h5')\n",
        "# model3 = load_model('my_model3.h5')\n",
        "# model4 = load_model('my_model4.h5')"
      ],
      "metadata": {
        "id": "qNsIxrgRjAc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_predict_C=model1.predict(X_train_C)\n",
        "test_predict_C=model1.predict(X_test_C)\n",
        "train_predict_C=scaler1.inverse_transform(train_predict_C)\n",
        "test_predict_C=scaler1.inverse_transform(test_predict_C)\n",
        "\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train_C,train_predict_C)), math.sqrt(mean_squared_error(ytest_C,test_predict_C))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CaVpD8sN3yi",
        "outputId": "718b1ae3-0cc4-4677-fa97-7e217567490f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 13ms/step\n",
            "4/4 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36151.22459111484, 36752.100970917636)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_O=model2.predict(X_train_O)\n",
        "test_predict_O=model2.predict(X_test_O)\n",
        "train_predict_O=scaler2.inverse_transform(train_predict_O)\n",
        "test_predict_O=scaler2.inverse_transform(test_predict_O)\n",
        "\n",
        "math.sqrt(mean_squared_error(y_train_O,train_predict_O)), math.sqrt(mean_squared_error(ytest_O,test_predict_O))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIzqcRWeUPOl",
        "outputId": "8cbb4a2f-d644-4d80-e5dd-acca734865dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 12ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36045.090907459016, 36554.137931083)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_H=model3.predict(X_train_H)\n",
        "test_predict_H=model3.predict(X_test_H)\n",
        "train_predict_H=scaler3.inverse_transform(train_predict_H)\n",
        "test_predict_H=scaler3.inverse_transform(test_predict_H)\n",
        "\n",
        "math.sqrt(mean_squared_error(y_train_H,train_predict_H)), math.sqrt(mean_squared_error(ytest_H,test_predict_H))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQKj1itUPTV",
        "outputId": "9f23ee90-3bd4-4623-dab0-cc157dbe13c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 13ms/step\n",
            "4/4 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36516.23535228484, 37086.86252196283)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_L=model4.predict(X_train_L)\n",
        "test_predict_L=model4.predict(X_test_L)\n",
        "train_predict_L=scaler4.inverse_transform(train_predict_L)\n",
        "test_predict_L=scaler4.inverse_transform(test_predict_L)\n",
        "\n",
        "math.sqrt(mean_squared_error(y_train_L,train_predict_L)), math.sqrt(mean_squared_error(ytest_L,test_predict_L))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG-r9DirUPW0",
        "outputId": "cf078fc5-bc35-4ec1-fa62-314aa6c818e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 13ms/step\n",
            "4/4 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35734.36805300566, 36338.49545952793)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "look_back=50\n",
        "trainPredictPlot1 = numpy.empty_like(df1)\n",
        "trainPredictPlot1[:, :] = np.nan\n",
        "trainPredictPlot1[look_back:len(train_predict_C)+look_back, :] = train_predict_C\n",
        "testPredictPlot1 = numpy.empty_like(df1)\n",
        "testPredictPlot1[:, :] = numpy.nan\n",
        "testPredictPlot1[len(train_predict_C)+(look_back*2)+1:len(df1)-1, :] = test_predict_C"
      ],
      "metadata": {
        "id": "-Rgd0d5uOAfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot2 = numpy.empty_like(df2)\n",
        "trainPredictPlot2[:, :] = np.nan\n",
        "trainPredictPlot2[look_back:len(train_predict_O)+look_back, :] = train_predict_O\n",
        "testPredictPlot2 = numpy.empty_like(df2)\n",
        "testPredictPlot2[:, :] = numpy.nan\n",
        "testPredictPlot2[len(train_predict_O)+(look_back*2)+1:len(df2)-1, :] = test_predict_O"
      ],
      "metadata": {
        "id": "8AReqCgnXH6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot3 = numpy.empty_like(df3)\n",
        "trainPredictPlot3[:, :] = np.nan\n",
        "trainPredictPlot3[look_back:len(train_predict_H)+look_back, :] = train_predict_H\n",
        "testPredictPlot3 = numpy.empty_like(df3)\n",
        "testPredictPlot3[:, :] = numpy.nan\n",
        "testPredictPlot3[len(train_predict_H)+(look_back*2)+1:len(df3)-1, :] = test_predict_H"
      ],
      "metadata": {
        "id": "gdp71A0hXH89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainPredictPlot4 = numpy.empty_like(df4)\n",
        "trainPredictPlot4[:, :] = np.nan\n",
        "trainPredictPlot4[look_back:len(train_predict_L)+look_back, :] = train_predict_L\n",
        "testPredictPlot4 = numpy.empty_like(df4)\n",
        "testPredictPlot4[:, :] = numpy.nan\n",
        "testPredictPlot4[len(train_predict_L)+(look_back*2)+1:len(df4)-1, :] = test_predict_L"
      ],
      "metadata": {
        "id": "tbZXBJ7tXH_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = test_data_close.shape[0]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acuYj-DDa9ec",
        "outputId": "7047a0bc-7d24-4b75-9d10-dff7a3b55921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_value = a - 50\n",
        "next_values = 5\n",
        "x_input=test_data_close[input_value:].reshape(1,-1)\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "lst_output_close=[]\n",
        "n_steps=50\n",
        "i=0\n",
        "while(i<next_values):\n",
        "    \n",
        "    if(len(temp_input)>50):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        yhat = model1.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        lst_output_close.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model1.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output_close.extend(yhat.tolist())\n",
        "        i=i+1"
      ],
      "metadata": {
        "id": "hR8gJpHMOAiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02b1712-8cd3-459d-91e5-9eb0d4fcab7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7705869]\n",
            "51\n",
            "1 day input [0.68122485 0.69202631 0.68891912 0.6680228  0.68278089 0.71110742\n",
            " 0.71561871 0.76855266 0.78307813 0.80072406 0.82057883 0.83796559\n",
            " 0.77803943 0.71650379 0.75226088 0.78273828 0.77489207 0.77814666\n",
            " 0.71462152 0.82728952 0.80623219 0.81693969 0.85134228 0.83889118\n",
            " 0.82006015 0.88739452 0.90588116 0.9200357  0.94678    0.99437556\n",
            " 0.97683232 0.93816922 0.94957842 1.         0.97631818 0.92509675\n",
            " 0.82813897 0.74498261 0.72199375 0.66840736 0.65838375 0.74638636\n",
            " 0.69253137 0.78913602 0.80458708 0.79521627 0.7876205  0.7535843\n",
            " 0.78989605 0.77058691]\n",
            "1 day output [[0.7525403]]\n",
            "2 day input [0.69202631 0.68891912 0.6680228  0.68278089 0.71110742 0.71561871\n",
            " 0.76855266 0.78307813 0.80072406 0.82057883 0.83796559 0.77803943\n",
            " 0.71650379 0.75226088 0.78273828 0.77489207 0.77814666 0.71462152\n",
            " 0.82728952 0.80623219 0.81693969 0.85134228 0.83889118 0.82006015\n",
            " 0.88739452 0.90588116 0.9200357  0.94678    0.99437556 0.97683232\n",
            " 0.93816922 0.94957842 1.         0.97631818 0.92509675 0.82813897\n",
            " 0.74498261 0.72199375 0.66840736 0.65838375 0.74638636 0.69253137\n",
            " 0.78913602 0.80458708 0.79521627 0.7876205  0.7535843  0.78989605\n",
            " 0.77058691 0.75254029]\n",
            "2 day output [[0.7298391]]\n",
            "3 day input [0.68891912 0.6680228  0.68278089 0.71110742 0.71561871 0.76855266\n",
            " 0.78307813 0.80072406 0.82057883 0.83796559 0.77803943 0.71650379\n",
            " 0.75226088 0.78273828 0.77489207 0.77814666 0.71462152 0.82728952\n",
            " 0.80623219 0.81693969 0.85134228 0.83889118 0.82006015 0.88739452\n",
            " 0.90588116 0.9200357  0.94678    0.99437556 0.97683232 0.93816922\n",
            " 0.94957842 1.         0.97631818 0.92509675 0.82813897 0.74498261\n",
            " 0.72199375 0.66840736 0.65838375 0.74638636 0.69253137 0.78913602\n",
            " 0.80458708 0.79521627 0.7876205  0.7535843  0.78989605 0.77058691\n",
            " 0.75254029 0.72983909]\n",
            "3 day output [[0.7039159]]\n",
            "4 day input [0.6680228  0.68278089 0.71110742 0.71561871 0.76855266 0.78307813\n",
            " 0.80072406 0.82057883 0.83796559 0.77803943 0.71650379 0.75226088\n",
            " 0.78273828 0.77489207 0.77814666 0.71462152 0.82728952 0.80623219\n",
            " 0.81693969 0.85134228 0.83889118 0.82006015 0.88739452 0.90588116\n",
            " 0.9200357  0.94678    0.99437556 0.97683232 0.93816922 0.94957842\n",
            " 1.         0.97631818 0.92509675 0.82813897 0.74498261 0.72199375\n",
            " 0.66840736 0.65838375 0.74638636 0.69253137 0.78913602 0.80458708\n",
            " 0.79521627 0.7876205  0.7535843  0.78989605 0.77058691 0.75254029\n",
            " 0.72983909 0.70391589]\n",
            "4 day output [[0.67636317]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_input=test_data_open[input_value:].reshape(1,-1)\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "lst_output_open=[]\n",
        "n_steps=50\n",
        "i=0\n",
        "while(i<next_values):\n",
        "    \n",
        "    if(len(temp_input)>50):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        # print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        yhat = model2.predict(x_input, verbose=0)\n",
        "        # print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        lst_output_open.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model2.predict(x_input, verbose=0)\n",
        "        # print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        # print(len(temp_input))\n",
        "        lst_output_open.extend(yhat.tolist())\n",
        "        i=i+1"
      ],
      "metadata": {
        "id": "6hgLw48TYR9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_input=test_data_high[input_value:].reshape(1,-1)\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "lst_output_high=[]\n",
        "n_steps=50\n",
        "i=0\n",
        "while(i<next_values):\n",
        "    \n",
        "    if(len(temp_input)>50):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        yhat = model3.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        lst_output_high.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model3.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output_high.extend(yhat.tolist())\n",
        "        i=i+1"
      ],
      "metadata": {
        "id": "NtAarzfsYR_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6685027-310f-419f-c371-8c32599cb774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77240294]\n",
            "51\n",
            "1 day input [0.65711733 0.67823682 0.66845724 0.68280795 0.67565217 0.68900534\n",
            " 0.69784851 0.74436434 0.75814777 0.78941632 0.79468177 0.81219264\n",
            " 0.81706698 0.72684901 0.73889629 0.76095219 0.79180284 0.77996639\n",
            " 0.69733446 0.80365268 0.80902355 0.80271215 0.82638951 0.84472244\n",
            " 0.80061991 0.86160045 0.89853861 0.89844624 0.91773309 0.98125398\n",
            " 1.         0.94043043 0.94234239 0.98571523 0.97024818 0.94014027\n",
            " 0.8846889  0.77049861 0.75477231 0.69484665 0.68733924 0.73371875\n",
            " 0.71882756 0.76593641 0.80381098 0.77099549 0.77808499 0.76571218\n",
            " 0.7647586  0.77240294]\n",
            "1 day output [[0.76161844]]\n",
            "2 day input [0.67823682 0.66845724 0.68280795 0.67565217 0.68900534 0.69784851\n",
            " 0.74436434 0.75814777 0.78941632 0.79468177 0.81219264 0.81706698\n",
            " 0.72684901 0.73889629 0.76095219 0.79180284 0.77996639 0.69733446\n",
            " 0.80365268 0.80902355 0.80271215 0.82638951 0.84472244 0.80061991\n",
            " 0.86160045 0.89853861 0.89844624 0.91773309 0.98125398 1.\n",
            " 0.94043043 0.94234239 0.98571523 0.97024818 0.94014027 0.8846889\n",
            " 0.77049861 0.75477231 0.69484665 0.68733924 0.73371875 0.71882756\n",
            " 0.76593641 0.80381098 0.77099549 0.77808499 0.76571218 0.7647586\n",
            " 0.77240294 0.76161844]\n",
            "2 day output [[0.7491209]]\n",
            "3 day input [0.66845724 0.68280795 0.67565217 0.68900534 0.69784851 0.74436434\n",
            " 0.75814777 0.78941632 0.79468177 0.81219264 0.81706698 0.72684901\n",
            " 0.73889629 0.76095219 0.79180284 0.77996639 0.69733446 0.80365268\n",
            " 0.80902355 0.80271215 0.82638951 0.84472244 0.80061991 0.86160045\n",
            " 0.89853861 0.89844624 0.91773309 0.98125398 1.         0.94043043\n",
            " 0.94234239 0.98571523 0.97024818 0.94014027 0.8846889  0.77049861\n",
            " 0.75477231 0.69484665 0.68733924 0.73371875 0.71882756 0.76593641\n",
            " 0.80381098 0.77099549 0.77808499 0.76571218 0.7647586  0.77240294\n",
            " 0.76161844 0.74912089]\n",
            "3 day output [[0.7353051]]\n",
            "4 day input [0.68280795 0.67565217 0.68900534 0.69784851 0.74436434 0.75814777\n",
            " 0.78941632 0.79468177 0.81219264 0.81706698 0.72684901 0.73889629\n",
            " 0.76095219 0.79180284 0.77996639 0.69733446 0.80365268 0.80902355\n",
            " 0.80271215 0.82638951 0.84472244 0.80061991 0.86160045 0.89853861\n",
            " 0.89844624 0.91773309 0.98125398 1.         0.94043043 0.94234239\n",
            " 0.98571523 0.97024818 0.94014027 0.8846889  0.77049861 0.75477231\n",
            " 0.69484665 0.68733924 0.73371875 0.71882756 0.76593641 0.80381098\n",
            " 0.77099549 0.77808499 0.76571218 0.7647586  0.77240294 0.76161844\n",
            " 0.74912089 0.73530507]\n",
            "4 day output [[0.72081506]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_input=test_data_low[input_value:].reshape(1,-1)\n",
        "\n",
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()\n",
        "\n",
        "lst_output_low=[]\n",
        "n_steps=50\n",
        "i=0\n",
        "while(i<next_values):\n",
        "    \n",
        "    if(len(temp_input)>50):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        # print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        yhat = model4.predict(x_input, verbose=0)\n",
        "        # print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        lst_output_low.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model4.predict(x_input, verbose=0)\n",
        "        # print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        # print(len(temp_input))\n",
        "        lst_output_low.extend(yhat.tolist())\n",
        "        i=i+1"
      ],
      "metadata": {
        "id": "4MDcn752YSCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_answer = pd.DataFrame()\n",
        "final_answer['Close'] = scaler1.inverse_transform(lst_output_close).tolist()\n",
        "final_answer['Open'] = scaler2.inverse_transform(lst_output_open).tolist()\n",
        "final_answer['High'] = scaler3.inverse_transform(lst_output_high).tolist()\n",
        "final_answer['Low'] = scaler4.inverse_transform(lst_output_low).tolist()\n",
        "final_answer"
      ],
      "metadata": {
        "id": "QnGH0d-fOTN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8edfac47-fff1-4b68-8e6a-c6686fa368fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Close                  Open                  High  \\\n",
              "0  [38902.602111819724]    [38178.1918688917]   [39251.06165200839]   \n",
              "1   [38700.77325326536]   [38138.31992536683]  [39128.379819865564]   \n",
              "2   [38446.88866500888]  [38044.387858378344]   [38986.21090483183]   \n",
              "3   [38156.97016087506]   [37923.48441624043]   [38829.04561497908]   \n",
              "4   [37848.82738513086]   [37789.30103889101]   [38664.21093074292]   \n",
              "\n",
              "                    Low  \n",
              "0   [38956.12070985928]  \n",
              "1  [38882.975580488695]  \n",
              "2   [38721.88724959632]  \n",
              "3   [38485.53144147611]  \n",
              "4   [38191.53510992658]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c439047b-400e-4360-8096-89235f5d1986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[38902.602111819724]</td>\n",
              "      <td>[38178.1918688917]</td>\n",
              "      <td>[39251.06165200839]</td>\n",
              "      <td>[38956.12070985928]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[38700.77325326536]</td>\n",
              "      <td>[38138.31992536683]</td>\n",
              "      <td>[39128.379819865564]</td>\n",
              "      <td>[38882.975580488695]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[38446.88866500888]</td>\n",
              "      <td>[38044.387858378344]</td>\n",
              "      <td>[38986.21090483183]</td>\n",
              "      <td>[38721.88724959632]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[38156.97016087506]</td>\n",
              "      <td>[37923.48441624043]</td>\n",
              "      <td>[38829.04561497908]</td>\n",
              "      <td>[38485.53144147611]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[37848.82738513086]</td>\n",
              "      <td>[37789.30103889101]</td>\n",
              "      <td>[38664.21093074292]</td>\n",
              "      <td>[38191.53510992658]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c439047b-400e-4360-8096-89235f5d1986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c439047b-400e-4360-8096-89235f5d1986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c439047b-400e-4360-8096-89235f5d1986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = scaler1.inverse_transform(lst_output_low)\n",
        "df5 = pd.DataFrame(df5)\n",
        "df5.plot()"
      ],
      "metadata": {
        "id": "i3D6elGH4IEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6ed2e145-fffc-4ceb-dfa1-731052ca5eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7cd22196a0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqRkuZ0inTZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}